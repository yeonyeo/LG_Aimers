{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPP+BL/Z1HpWjAw697nxzGp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonyeo/LG_Aimers/blob/main/basesline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvXq6FELi5ic"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "D9L030-Oi9q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 16, 50\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Bivssa-9jA35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('./train/train.csv')"
      ],
      "metadata": {
        "id": "yM6YJEhAjBah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiOutputLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=1, hidden_dim=64, num_layers=2, output_dim=7):\n",
        "        super(MultiOutputLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out[:, -1, :])  # (B, output_dim)"
      ],
      "metadata": {
        "id": "XZARq-NAjDGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lstm(train_df):\n",
        "    trained_models = {}\n",
        "\n",
        "    for store_menu, group in tqdm(train_df.groupby(['영업장명_메뉴명']), desc ='Training LSTM'):\n",
        "        store_train = group.sort_values('영업일자').copy()\n",
        "        if len(store_train) < LOOKBACK + PREDICT:\n",
        "            continue\n",
        "\n",
        "        features = ['매출수량']\n",
        "        scaler = MinMaxScaler()\n",
        "        store_train[features] = scaler.fit_transform(store_train[features])\n",
        "        train_vals = store_train[features].values  # shape: (N, 1)\n",
        "\n",
        "        # 시퀀스 구성\n",
        "        X_train, y_train = [], []\n",
        "        for i in range(len(train_vals) - LOOKBACK - PREDICT + 1):\n",
        "            X_train.append(train_vals[i:i+LOOKBACK])\n",
        "            y_train.append(train_vals[i+LOOKBACK:i+LOOKBACK+PREDICT, 0])\n",
        "\n",
        "        X_train = torch.tensor(X_train).float().to(DEVICE)\n",
        "        y_train = torch.tensor(y_train).float().to(DEVICE)\n",
        "\n",
        "        model = MultiOutputLSTM(input_dim=1, output_dim=PREDICT).to(DEVICE)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        model.train()\n",
        "        for epoch in range(EPOCHS):\n",
        "            idx = torch.randperm(len(X_train))\n",
        "            for i in range(0, len(X_train), BATCH_SIZE):\n",
        "                batch_idx = idx[i:i+BATCH_SIZE]\n",
        "                X_batch, y_batch = X_train[batch_idx], y_train[batch_idx]\n",
        "                output = model(X_batch)\n",
        "                loss = criterion(output, y_batch)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        trained_models[store_menu] = {\n",
        "            'model': model.eval(),\n",
        "            'scaler': scaler,\n",
        "            'last_sequence': train_vals[-LOOKBACK:]  # (28, 1)\n",
        "        }\n",
        "\n",
        "    return trained_models"
      ],
      "metadata": {
        "id": "a4_KhEBhjE8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습\n",
        "trained_models = train_lstm(train)"
      ],
      "metadata": {
        "id": "rPdWqIt8jIRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_lstm(test_df, trained_models, test_prefix: str):\n",
        "    results = []\n",
        "\n",
        "    for store_menu, store_test in test_df.groupby(['영업장명_메뉴명']):\n",
        "        key = store_menu\n",
        "        if key not in trained_models:\n",
        "            continue\n",
        "\n",
        "        model = trained_models[key]['model']\n",
        "        scaler = trained_models[key]['scaler']\n",
        "\n",
        "        store_test_sorted = store_test.sort_values('영업일자')\n",
        "        recent_vals = store_test_sorted['매출수량'].values[-LOOKBACK:]\n",
        "        if len(recent_vals) < LOOKBACK:\n",
        "            continue\n",
        "\n",
        "        # 정규화\n",
        "        recent_vals = scaler.transform(recent_vals.reshape(-1, 1))\n",
        "        x_input = torch.tensor([recent_vals]).float().to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(x_input).squeeze().cpu().numpy()\n",
        "\n",
        "        # 역변환\n",
        "        restored = []\n",
        "        for i in range(PREDICT):\n",
        "            dummy = np.zeros((1, 1))\n",
        "            dummy[0, 0] = pred_scaled[i]\n",
        "            restored_val = scaler.inverse_transform(dummy)[0, 0]\n",
        "            restored.append(max(restored_val, 0))\n",
        "\n",
        "        # 예측일자: TEST_00+1일 ~ TEST_00+7일\n",
        "        pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(PREDICT)]\n",
        "\n",
        "        for d, val in zip(pred_dates, restored):\n",
        "            results.append({\n",
        "                '영업일자': d,\n",
        "                '영업장명_메뉴명': store_menu,\n",
        "                '매출수량': val\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "beTQFylfjI9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds = []\n",
        "\n",
        "# 모든 test_*.csv 순회\n",
        "test_files = sorted(glob.glob('./test/TEST_*.csv'))\n",
        "\n",
        "for path in test_files:\n",
        "    test_df = pd.read_csv(path)\n",
        "\n",
        "    # 파일명에서 접두어 추출 (예: TEST_00)\n",
        "    filename = os.path.basename(path)\n",
        "    test_prefix = re.search(r'(TEST_\\d+)', filename).group(1)\n",
        "\n",
        "    pred_df = predict_lstm(test_df, trained_models, test_prefix)\n",
        "    all_preds.append(pred_df)\n",
        "\n",
        "full_pred_df = pd.concat(all_preds, ignore_index=True)"
      ],
      "metadata": {
        "id": "18PpvKFsjLr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_submission_format(pred_df: pd.DataFrame, sample_submission: pd.DataFrame):\n",
        "    # (영업일자, 메뉴) → 매출수량 딕셔너리로 변환\n",
        "    pred_dict = dict(zip(\n",
        "        zip(pred_df['영업일자'], pred_df['영업장명_메뉴명']),\n",
        "        pred_df['매출수량']\n",
        "    ))\n",
        "\n",
        "    final_df = sample_submission.copy()\n",
        "\n",
        "    for row_idx in final_df.index:\n",
        "        date = final_df.loc[row_idx, '영업일자']\n",
        "        for col in final_df.columns[1:]:  # 메뉴명들\n",
        "            final_df.loc[row_idx, col] = pred_dict.get((date, col), 0)\n",
        "\n",
        "    return final_df"
      ],
      "metadata": {
        "id": "3HLOUpqIjNbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv('./sample_submission.csv')\n",
        "submission = convert_to_submission_format(full_pred_df, sample_submission)\n",
        "submission.to_csv('baseline_submission.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "5ipSZV1DjPee"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}