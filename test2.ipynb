{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Er9iSq0zs_oVxUoe-ZwLoyD3fe_YAej2",
      "authorship_tag": "ABX9TyO2qW3L+tyMdU3OhoG18wEG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonyeo/LG_Aimers/blob/main/test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuooXfyKycg6",
        "outputId": "c5233b44-a591-41ac-ddfb-fff148e6e3d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 0s (46.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "67DpvkR9zIx4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 16, 50\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "9XQXdjPdzKxl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/open/train/train.csv')"
      ],
      "metadata": {
        "id": "FM0pRZSDzMY2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "print(train.isna().sum())\n",
        "\n",
        "# 음수 판매량 개수 확인\n",
        "print(\"음수 매출 개수:\", (train['매출수량']<0).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbl-fS698PaC",
        "outputId": "49441f76-f278-4057-8378-cdd54bbe6510"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영업일자        0\n",
            "영업장명_메뉴명    0\n",
            "매출수량        0\n",
            "dtype: int64\n",
            "음수 매출 개수: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 음수 이상치 0으로 처리\n",
        "train['매출수량'] = train['매출수량'].clip(lower=0)"
      ],
      "metadata": {
        "id": "M677NRoJfhqN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "print(train.isna().sum())\n",
        "\n",
        "# 음수 판매량 개수 확인\n",
        "print(\"음수 매출 개수:\", (train['매출수량']<0).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iA9_bu0fxUA",
        "outputId": "46d39b5d-1454-4642-e7a9-19193d0ae567"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영업일자        0\n",
            "영업장명_메뉴명    0\n",
            "매출수량        0\n",
            "dtype: int64\n",
            "음수 매출 개수: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# 카테고리 인코딩\n",
        "# 업장명, 메뉴명 분리\n",
        "train[['업장명', '메뉴명']] = train['영업장명_메뉴명'].str.split('_', expand=True)\n",
        "# 각각 인코딩\n",
        "le1 = LabelEncoder()\n",
        "le2 = LabelEncoder()\n",
        "train['업장명'] = le1.fit_transform(train['업장명'])\n",
        "train['메뉴명'] = le2.fit_transform(train['메뉴명'])"
      ],
      "metadata": {
        "id": "YNm-DIGBxg6y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일링\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "train[['매출수량']] = scaler.fit_transform(train[['매출수량']])"
      ],
      "metadata": {
        "id": "eWaWUT5Qx1EK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처엔지니링\n",
        "train['영업일자'] = pd.to_datetime(train['영업일자'])\n",
        "# 요일 컬럼 생성\n",
        "train['요일'] = pd.to_datetime(train['영업일자']).dt.dayofweek  # 0=월~6=일\n",
        "# 주말 플래그\n",
        "train['is_weekend'] = train['요일'].isin([5, 6]).astype(int)\n",
        "# 금요일, 토요일, 일요일 개별 플래그\n",
        "train['is_friday'] = (train['요일'] == 4).astype(int)\n",
        "train['is_saturday'] = (train['요일'] == 5).astype(int)\n",
        "train['is_sunday'] = (train['요일'] == 6).astype(int)\n",
        "# 공휴일 플래그\n",
        "holidays = ['2023-05-05', '2023-08-15', '2023-09-28', ...]  # 직접 입력\n",
        "train['is_holiday'] = train['영업일자'].astype(str).isin(holidays).astype(int)\n",
        "\n",
        "# 월, 계절\n",
        "train['월'] = train['영업일자'].dt.month\n",
        "train['계절'] = train['월'].map({12:'겨울', 1:'겨울', 2:'겨울', 3:'봄', 4:'봄', 5:'봄', 6:'여름', 7:'여름', 8:'여름', 9:'가을', 10:'가을', 11:'가을'})\n",
        "train = pd.get_dummies(train, columns=['계절'])"
      ],
      "metadata": {
        "id": "cvQ1xprkyTA1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for col in ['영업장명_메뉴명', '요일']:\n",
        "    le = LabelEncoder()\n",
        "    train[col] = le.fit_transform(train[col])"
      ],
      "metadata": {
        "id": "YcznrhrBJK6L"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_day = train['영업일자'].sort_values().unique()[-7]  # 마지막 7일 기준\n",
        "train_set = train[train['영업일자'] < split_day]\n",
        "valid_set = train[train['영업일자'] >= split_day]\n",
        "\n",
        "X_train = train_set.drop(['매출수량', '영업일자'], axis=1)\n",
        "y_train = train_set['매출수량']\n",
        "X_valid = valid_set.drop(['매출수량', '영업일자'], axis=1)\n",
        "y_valid = valid_set['매출수량']"
      ],
      "metadata": {
        "id": "h2Lj4lWi1i0z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost 모델 TEST\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb = XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    random_state=42,\n",
        "    tree_method='hist'\n",
        ")\n",
        "xgb.fit(X_train, y_train)\n",
        "xgb_pred = xgb.predict(X_valid)\n",
        "\n",
        "# 평가\n",
        "def smape(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    mask = y_true != 0\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    smape_vals = np.abs(y_true - y_pred) / denominator\n",
        "    return np.mean(smape_vals) * 100\n",
        "\n",
        "print(\"XGBoost SMAPE:\", smape(y_valid, xgb_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPPu--aj1uDc",
        "outputId": "922b0cd5-81a6-4719-8329-b940e74a9a25"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost SMAPE: 66.34762024748113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM test\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "lgbm = LGBMRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "lgbm.fit(X_train, y_train)\n",
        "lgbm_pred = lgbm.predict(X_valid)\n",
        "\n",
        "print(\"LightGBM SMAPE:\", smape(y_valid, lgbm_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6AefLFaRUKe",
        "outputId": "6696e175-28b1-4b5d-fb00-bf54f92d599b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 393\n",
            "[LightGBM] [Info] Number of data points in the train set: 101325, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 0.007801\n",
            "LightGBM SMAPE: 71.96395544420176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMxPp5fwTR5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}