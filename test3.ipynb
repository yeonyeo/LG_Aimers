{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Er9iSq0zs_oVxUoe-ZwLoyD3fe_YAej2",
      "authorship_tag": "ABX9TyONej0Y5WeBDEtZXFbA1WIO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonyeo/LG_Aimers/blob/main/test3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuooXfyKycg6",
        "outputId": "02cd74fc-8ef0-476d-fe0e-d0936cbc9069"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20200506-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "67DpvkR9zIx4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 16, 50\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "9XQXdjPdzKxl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/open/train/train.csv')"
      ],
      "metadata": {
        "id": "FM0pRZSDzMY2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "print(train.isna().sum())\n",
        "\n",
        "# 음수 판매량 개수 확인\n",
        "print(\"음수 매출 개수:\", (train['매출수량']<0).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbl-fS698PaC",
        "outputId": "6393c8d5-2563-46ba-8549-23bb2265c653"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영업일자        0\n",
            "영업장명_메뉴명    0\n",
            "매출수량        0\n",
            "dtype: int64\n",
            "음수 매출 개수: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 음수 이상치 0으로 처리\n",
        "train['매출수량'] = train['매출수량'].clip(lower=0)"
      ],
      "metadata": {
        "id": "M677NRoJfhqN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 확인\n",
        "print(train.isna().sum())\n",
        "\n",
        "# 음수 판매량 개수 확인\n",
        "print(\"음수 매출 개수:\", (train['매출수량']<0).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iA9_bu0fxUA",
        "outputId": "2be55e9c-96fe-48e9-cb1b-c29a5402331d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영업일자        0\n",
            "영업장명_메뉴명    0\n",
            "매출수량        0\n",
            "dtype: int64\n",
            "음수 매출 개수: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# 카테고리 인코딩\n",
        "# 업장명, 메뉴명 분리\n",
        "train[['업장명', '메뉴명']] = train['영업장명_메뉴명'].str.split('_', expand=True)\n",
        "# 각각 인코딩\n",
        "le1 = LabelEncoder()\n",
        "le2 = LabelEncoder()\n",
        "train['업장명'] = le1.fit_transform(train['업장명'])\n",
        "train['메뉴명'] = le2.fit_transform(train['메뉴명'])"
      ],
      "metadata": {
        "id": "YNm-DIGBxg6y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 스케일링\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "train[['매출수량']] = scaler.fit_transform(train[['매출수량']])"
      ],
      "metadata": {
        "id": "eWaWUT5Qx1EK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처엔지니링\n",
        "train['영업일자'] = pd.to_datetime(train['영업일자'])\n",
        "# 요일 컬럼 생성\n",
        "train['요일'] = pd.to_datetime(train['영업일자']).dt.dayofweek  # 0=월~6=일\n",
        "# 주말 플래그\n",
        "train['is_weekend'] = train['요일'].isin([5, 6]).astype(int)\n",
        "# 금요일, 토요일, 일요일 개별 플래그\n",
        "train['is_friday'] = (train['요일'] == 4).astype(int)\n",
        "train['is_saturday'] = (train['요일'] == 5).astype(int)\n",
        "train['is_sunday'] = (train['요일'] == 6).astype(int)\n",
        "# 공휴일 플래그\n",
        "holidays = ['2023-05-05', '2023-08-15', '2023-09-28', ...]  # 직접 입력\n",
        "train['is_holiday'] = train['영업일자'].astype(str).isin(holidays).astype(int)\n",
        "\n",
        "# 월, 계절\n",
        "train['월'] = train['영업일자'].dt.month\n",
        "train['계절'] = train['월'].map({12:'겨울', 1:'겨울', 2:'겨울', 3:'봄', 4:'봄', 5:'봄', 6:'여름', 7:'여름', 8:'여름', 9:'가을', 10:'가을', 11:'가을'})\n",
        "train = pd.get_dummies(train, columns=['계절'])\n",
        "# 최근 N일(7, 14, 28)간 매출 평균\n",
        "for window in [7, 14, 28]:\n",
        "    train[f'rolling_mean_{window}'] = train.groupby('영업장명_메뉴명')['매출수량']\\\n",
        "        .transform(lambda x: x.rolling(window, min_periods=1).mean().shift(1))"
      ],
      "metadata": {
        "id": "cvQ1xprkyTA1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for col in ['영업장명_메뉴명', '요일']:\n",
        "    le = LabelEncoder()\n",
        "    train[col] = le.fit_transform(train[col])"
      ],
      "metadata": {
        "id": "YcznrhrBJK6L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_day = train['영업일자'].sort_values().unique()[-7]  # 마지막 7일 기준\n",
        "train_set = train[train['영업일자'] < split_day]\n",
        "valid_set = train[train['영업일자'] >= split_day]\n",
        "\n",
        "X_train = train_set.drop(['매출수량', '영업일자'], axis=1)\n",
        "y_train = train_set['매출수량']\n",
        "X_valid = valid_set.drop(['매출수량', '영업일자'], axis=1)\n",
        "y_valid = valid_set['매출수량']"
      ],
      "metadata": {
        "id": "h2Lj4lWi1i0z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NaN 처리\n",
        "train = train.fillna(0)\n",
        "# 숫자형만 남기고 결측값 채우기\n",
        "X_train = X_train.select_dtypes(include=[np.number]).fillna(0)\n",
        "X_valid = X_valid.select_dtypes(include=[np.number]).fillna(0)"
      ],
      "metadata": {
        "id": "eua5eHkg0GYz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost 모델 TEST\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb = XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    random_state=42,\n",
        "    tree_method='hist'\n",
        ")\n",
        "xgb.fit(X_train, y_train)\n",
        "xgb_pred = xgb.predict(X_valid)\n",
        "\n",
        "# 평가\n",
        "def smape(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    mask = y_true != 0\n",
        "    y_true = y_true[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
        "    smape_vals = np.abs(y_true - y_pred) / denominator\n",
        "    return np.mean(smape_vals) * 100\n",
        "\n",
        "print(\"XGBoost SMAPE:\", smape(y_valid, xgb_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPPu--aj1uDc",
        "outputId": "8fb76322-5daf-450e-a9d7-8be239f09126"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost SMAPE: 67.38695500325683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM test\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "lgbm = LGBMRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "lgbm.fit(X_train, y_train)\n",
        "lgbm_pred = lgbm.predict(X_valid)\n",
        "\n",
        "print(\"LightGBM SMAPE:\", smape(y_valid, lgbm_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6AefLFaRUKe",
        "outputId": "a1ec25cf-0699-4f10-f785-d26b02517a30"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005768 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1173\n",
            "[LightGBM] [Info] Number of data points in the train set: 101325, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 0.007801\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM SMAPE: 64.99037711798061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMxPp5fwTR5E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}